{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7dc0cc1",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; color:red;\">\n",
    "    <h2>Retail Sales Case Study</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08714a3d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#e0f2f1; padding:10px\">We are given a dataset from a Retail gaint. The dataset contains information on : <br> <p>1. Demographics of the customers, <b><i>demographics.txt</i></b> <br> 2. Purchase Behaviour, <b><i>behaviour.json</i></b> <br>\n",
    "3. Response to various marketing campaigns run, <b><i>campaign.json</i></b></p> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c35e00",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#dcedc8; padding:10px\"><h3>Business Problem</h3> <br>The retailer wants to understand what kind of customers respond to different campaigns. To arrive at a reasonable answer to the above question, you've been tasked to analyze this dataset. Below are some pointed business questions you are required to answer. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635c205",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#dcedc8; padding:10px\">\n",
    "    <h3>Data Quality and Check (Task 1)</h3>\n",
    "<br>1.\n",
    "Create a consolidated view of data by joining the data present in three files.\n",
    "<br>2.\n",
    "Are there any variables where you will need to clean the raw data, what kind of cleaning will be needed?\n",
    "<br>3.\n",
    "Create a data quality report after doing the necessary cleaning and joining of the files by:\n",
    "<br> &nbsp;&nbsp;&nbsp;•\n",
    "Doing univariates for continuous variables (compute: percentage of missing values, percentage of terms which are zero, mean, 25th, 50th, 75th, 90th and 95th percentile, min and max)\n",
    "<br> &nbsp;&nbsp;&nbsp;•\n",
    "Doing univariates for categorical variables (compute:percentage of missing values, number of unique values)\n",
    "<br>4.\n",
    "Are there any extreme values of variables representing income, amount of money spent on various categories, recency of purchase?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16586f09",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\"><b>1.</b> To create a consolidated view of data by joining the data present in three files (two JSON files and one text file), can follow these general steps:<br>\n",
    "<b>Read the Files:</b> Begin by reading the data from each of the three files into Python script.<br>\n",
    "<b>Parse JSON Files:</b> Parse the data from the JSON files into Python dictionaries or objects.<br>\n",
    "<b>Process Text File:</b> Read and process the data from the text file according to its format.<br>\n",
    "<b>Combine Data:</b> Once you have the data from all three sources, combine them based on a common identifier.<br>\n",
    "<b>Consolidate Data:</b> Consolidate the combined data into a single data structure, such as a list of dictionaries or a pandas DataFrame.<br>\n",
    "<b>Output the Consolidated Data:</b> Depending on requirement, we can output the consolidated data in a CSV format.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f746352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9435402e",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\"><i>For behaviour.json</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f14b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing JSON module\n",
    "import json\n",
    "\n",
    "# Read data of BEHAVIOUR.JSON file (file should be in same directory)\n",
    "with open(\"behaviour.json\",'r') as f1:\n",
    "   data_1 = json.load(f1)\n",
    "#print(data_1) # usually data looks in json file\n",
    "#data_1 # in more readable manner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ab942",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\">After seeing data in <b><i>`behaviour.json`</i></b> file we realized that the data stored as list of dictionaries, where each dictionary represents a customer's data. Each dictionary contains various key-value pairs representing different attributes of the customer, such as their ID, recency, purchase amounts for different product categories (e.g., wines, fruits, meat products), number of purchases through different channels (e.g., web, catalog, store), and number of web visits per month.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee10ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store data of behavior.json\n",
    "rows = []\n",
    "\n",
    "# Loop through each dictionary in the list\n",
    "for items in data_1:\n",
    "    # Extract the key (ID) and the corresponding dictionary\n",
    "    id_ = list(items.keys())[0]\n",
    "    values = items[id_]\n",
    "\n",
    "    # Create a dictionary with Id as a key and value\n",
    "    row = {'ID':id_}\n",
    "    row.update(values)\n",
    "    rows.append(row)\n",
    "\n",
    "# Creating DataFrame\n",
    "df_behaviour = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d16333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  Recency  MntWines  MntFruits  MntMeatProducts  MntFishProducts  \\\n",
      "0   ID_1826        0       189        104              379              111   \n",
      "1      ID_1        0       464          5               64                7   \n",
      "2  ID_10476        0       134         11               59               15   \n",
      "3   ID_1386        0        10          0                1                0   \n",
      "4   ID_5371        0         6         16               24               11   \n",
      "\n",
      "   MntSweetProducts  MntGoldProds  NumDealsPurchases  NumWebPurchases  \\\n",
      "0               189           218                  1                4   \n",
      "1                 0            37                  1                7   \n",
      "2                 2            30                  1                3   \n",
      "3                 0             0                  1                1   \n",
      "4                 0            34                  2                3   \n",
      "\n",
      "   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  \n",
      "0                    4                  6                  1  \n",
      "1                    3                  7                  5  \n",
      "2                    2                  5                  2  \n",
      "3                    0                  2                  7  \n",
      "4                    1                  2                  7  \n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame\n",
    "print(df_behaviour.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70352db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Recency  MntWines  MntFruits  MntMeatProducts  MntFishProducts  \\\n",
      "0   1826        0       189        104              379              111   \n",
      "1      1        0       464          5               64                7   \n",
      "2  10476        0       134         11               59               15   \n",
      "3   1386        0        10          0                1                0   \n",
      "4   5371        0         6         16               24               11   \n",
      "\n",
      "   MntSweetProducts  MntGoldProds  NumDealsPurchases  NumWebPurchases  \\\n",
      "0               189           218                  1                4   \n",
      "1                 0            37                  1                7   \n",
      "2                 2            30                  1                3   \n",
      "3                 0             0                  1                1   \n",
      "4                 0            34                  2                3   \n",
      "\n",
      "   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  \n",
      "0                    4                  6                  1  \n",
      "1                    3                  7                  5  \n",
      "2                    2                  5                  2  \n",
      "3                    0                  2                  7  \n",
      "4                    1                  2                  7  \n"
     ]
    }
   ],
   "source": [
    "# Remove the 'ID_' prefix from the key 'Id' and store the result\n",
    "df_behaviour[\"ID\"] = df_behaviour['ID'].str.replace('ID_','')\n",
    "print(df_behaviour.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3e6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving DataFrame to a CSV file\n",
    "df1 = df_behaviour.to_csv('behaviour.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b4ea15",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\"><i>For campaign.json</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b5384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data of CAMPAIGN.JSON file (file should be in same directory as file)\n",
    "with open(\"campaign.json\",'r') as f2:\n",
    "   data_2 = json.load(f2)\n",
    "#print(data_2) # usually data looks in json file\n",
    "#data_2 # in more readable manner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a816c0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\">After seeing data in <b><i>`campaign.json`</i></b> file we realized that the data stored as list of dictionaries, where each dictionary represents a customer's data.<br> Each dictionary contains various key-value pairs representing different Attributes related to campaign acceptance, such as 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', and 'AcceptedCmp5'.<br>\n",
    "Attributes related to other responses, such as 'Response' and 'Complain'.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49eed27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initailize an empty list to store data of behavior.json\n",
    "rows = []\n",
    "\n",
    "# Iterate over each dictionary in the list\n",
    "for items in data_2:\n",
    "    # Extract the Id and values from the dictionary\n",
    "    id_ = list(items.keys())[0]\n",
    "    values = items[id_]\n",
    "\n",
    "    # Create a dictionary with Id as a key and value\n",
    "    row = {'ID':id_}\n",
    "    row.update(values)\n",
    "    rows.append(row)\n",
    "\n",
    "# Creating DataFrame\n",
    "df_campaign = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95c5c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  AcceptedCmp1  AcceptedCmp2  AcceptedCmp3  AcceptedCmp4  \\\n",
      "0   ID_1826             0             0             0             0   \n",
      "1      ID_1             0             1             0             0   \n",
      "2  ID_10476             0             0             0             0   \n",
      "3   ID_1386             0             0             0             0   \n",
      "4   ID_5371             0             0             1             0   \n",
      "\n",
      "   AcceptedCmp5  Response  Complain  \n",
      "0             0         1         0  \n",
      "1             0         1         0  \n",
      "2             0         0         0  \n",
      "3             0         0         0  \n",
      "4             0         1         0  \n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame\n",
    "print(df_campaign.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47fcb185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  AcceptedCmp1  AcceptedCmp2  AcceptedCmp3  AcceptedCmp4  \\\n",
      "0   1826             0             0             0             0   \n",
      "1      1             0             1             0             0   \n",
      "2  10476             0             0             0             0   \n",
      "3   1386             0             0             0             0   \n",
      "4   5371             0             0             1             0   \n",
      "\n",
      "   AcceptedCmp5  Response  Complain  \n",
      "0             0         1         0  \n",
      "1             0         1         0  \n",
      "2             0         0         0  \n",
      "3             0         0         0  \n",
      "4             0         1         0  \n"
     ]
    }
   ],
   "source": [
    "# Remove the 'ID_' prefix from the key 'Id' and store the result\n",
    "df_campaign[\"ID\"] = df_campaign['ID'].str.replace('ID_','')\n",
    "print(df_campaign.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe266b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving DataFrame to a CSV file\n",
    "df2 = df_campaign.to_csv('campaign.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9926ca1",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\"><i>For demographics.txt</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21c2edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Year_Birth   Education Marital_Status      Income   Kidhome  \\\n",
      "0   1826        1970  Graduation       Divorced  $84,835.00         0   \n",
      "1      1        1961  Graduation         Single  $57,091.00         0   \n",
      "2  10476        1958  Graduation        Married  $67,267.00         0   \n",
      "3   1386        1967  Graduation       Together  $32,474.00         1   \n",
      "4   5371        1989  Graduation         Single  $21,474.00         1   \n",
      "\n",
      "   Teenhome Dt_Customer Country  \n",
      "0         0     6/16/14      SP  \n",
      "1         0     6/15/14      CA  \n",
      "2         1     5/13/14      US  \n",
      "3         1     5/11/14     AUS  \n",
      "4         0      4/8/14      SP  \n"
     ]
    }
   ],
   "source": [
    "# Read the text file into a DataFrame\n",
    "df_demographics = pd.read_csv('demographics.txt', delimiter='\\t')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_demographics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5cac0f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\">After seeing data in <b><i>`demographics.txt`</i></b> file we realized that the data appears to be structured tabular data with various columns. Each row represents information about a customer, and each column represents a specific attribute of the customer, such as ID, birth year, education, marital status, income, number of kids at home, number of teenagers at home, date of customer registration, and country.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aef015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving DataFrame to a CSV file\n",
    "df3 = df_demographics.to_csv('demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd807c0a",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\"><i>Merging data</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e620f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'ID' column in behaviour file: object\n",
      "Data type of 'ID' column in campaign file: object\n",
      "Data type of 'ID' column in demographics file: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the data type of the 'ID' column of behaviour file\n",
    "id_dtype1 = df_behaviour['ID'].dtype\n",
    "print(\"Data type of 'ID' column in behaviour file:\", id_dtype1)\n",
    "\n",
    "# Check the data type of the 'ID' column of campaign file\n",
    "id_dtype2 = df_campaign['ID'].dtype\n",
    "print(\"Data type of 'ID' column in campaign file:\", id_dtype2)\n",
    "\n",
    "# Check the data type of the 'ID' column of demographics file\n",
    "id_dtype3 = df_demographics['ID'].dtype\n",
    "print(\"Data type of 'ID' column in demographics file:\", id_dtype3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed4821",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\">Since the 'ID' column has different data types in each file, we need to ensure consistency before merging. We'll convert the 'ID' column in the behaviour and campaign files to the same data type as the demographics file (int64) before merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d0270b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Year_Birth   Education Marital_Status      Income   Kidhome  \\\n",
      "0   1826        1970  Graduation       Divorced  $84,835.00         0   \n",
      "1      1        1961  Graduation         Single  $57,091.00         0   \n",
      "2  10476        1958  Graduation        Married  $67,267.00         0   \n",
      "3   1386        1967  Graduation       Together  $32,474.00         1   \n",
      "4   5371        1989  Graduation         Single  $21,474.00         1   \n",
      "\n",
      "   Teenhome Dt_Customer Country  Recency  ...  NumCatalogPurchases  \\\n",
      "0         0     6/16/14      SP        0  ...                    4   \n",
      "1         0     6/15/14      CA        0  ...                    3   \n",
      "2         1     5/13/14      US        0  ...                    2   \n",
      "3         1     5/11/14     AUS        0  ...                    0   \n",
      "4         0      4/8/14      SP        0  ...                    1   \n",
      "\n",
      "   NumStorePurchases  NumWebVisitsMonth  AcceptedCmp1  AcceptedCmp2  \\\n",
      "0                  6                  1             0             0   \n",
      "1                  7                  5             0             1   \n",
      "2                  5                  2             0             0   \n",
      "3                  2                  7             0             0   \n",
      "4                  2                  7             0             0   \n",
      "\n",
      "   AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  Response  Complain  \n",
      "0             0             0             0         1         0  \n",
      "1             0             0             0         1         0  \n",
      "2             0             0             0         0         0  \n",
      "3             0             0             0         0         0  \n",
      "4             1             0             0         1         0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'ID' column to int64 of the behaviour file\n",
    "df_behaviour['ID'] = df_behaviour['ID'].astype(int)\n",
    "\n",
    "# Convert 'ID' column to int64 of the campaign file \n",
    "df_campaign['ID'] = df_campaign['ID'].astype(int)\n",
    "\n",
    "# Merge the dataframes\n",
    "df_merged = pd.merge(df_demographics, df_behaviour, on='ID', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_campaign, on='ID', how='inner')\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "df_merged.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "# Display merged data\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5c09a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#e6e6fa; padding:10px\"><h3>2. To determine if there are any variables in the raw data that require cleaning, we need to assess the data for potential issues such as missing values, inconsistencies, outliers, or formatting errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb5b267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Country</th>\n",
       "      <th>Recency</th>\n",
       "      <th>...</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>Response</th>\n",
       "      <th>Complain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1826</td>\n",
       "      <td>1970</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>$84,835.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/16/14</td>\n",
       "      <td>SP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1961</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>$57,091.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/15/14</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10476</td>\n",
       "      <td>1958</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>$67,267.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5/13/14</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1386</td>\n",
       "      <td>1967</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>$32,474.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5/11/14</td>\n",
       "      <td>AUS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5371</td>\n",
       "      <td>1989</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>$21,474.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4/8/14</td>\n",
       "      <td>SP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Year_Birth   Education Marital_Status       Income  Kidhome  \\\n",
       "0   1826        1970  Graduation       Divorced  $84,835.00         0   \n",
       "1      1        1961  Graduation         Single  $57,091.00         0   \n",
       "2  10476        1958  Graduation        Married  $67,267.00         0   \n",
       "3   1386        1967  Graduation       Together  $32,474.00         1   \n",
       "4   5371        1989  Graduation         Single  $21,474.00         1   \n",
       "\n",
       "   Teenhome Dt_Customer Country  Recency  ...  NumCatalogPurchases  \\\n",
       "0         0     6/16/14      SP        0  ...                    4   \n",
       "1         0     6/15/14      CA        0  ...                    3   \n",
       "2         1     5/13/14      US        0  ...                    2   \n",
       "3         1     5/11/14     AUS        0  ...                    0   \n",
       "4         0      4/8/14      SP        0  ...                    1   \n",
       "\n",
       "   NumStorePurchases  NumWebVisitsMonth  AcceptedCmp1  AcceptedCmp2  \\\n",
       "0                  6                  1             0             0   \n",
       "1                  7                  5             0             1   \n",
       "2                  5                  2             0             0   \n",
       "3                  2                  7             0             0   \n",
       "4                  2                  7             0             0   \n",
       "\n",
       "   AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  Response  Complain  \n",
       "0             0             0             0         1         0  \n",
       "1             0             0             0         1         0  \n",
       "2             0             0             0         0         0  \n",
       "3             0             0             0         0         0  \n",
       "4             1             0             0         1         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from merged_data.csv file\n",
    "data = pd.read_csv('merged_data.csv')\n",
    "\n",
    "# Trim column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Display first 5 rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e455a58e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatypes in the dataset and their respective value counts:\n",
      "int64     23\n",
      "object     5\n",
      "dtype: int64\n",
      "------------------------------------------------------------\n",
      "Data Type: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   ID                   2240 non-null   int64\n",
      " 1   Year_Birth           2240 non-null   int64\n",
      " 2   Kidhome              2240 non-null   int64\n",
      " 3   Teenhome             2240 non-null   int64\n",
      " 4   Recency              2240 non-null   int64\n",
      " 5   MntWines             2240 non-null   int64\n",
      " 6   MntFruits            2240 non-null   int64\n",
      " 7   MntMeatProducts      2240 non-null   int64\n",
      " 8   MntFishProducts      2240 non-null   int64\n",
      " 9   MntSweetProducts     2240 non-null   int64\n",
      " 10  MntGoldProds         2240 non-null   int64\n",
      " 11  NumDealsPurchases    2240 non-null   int64\n",
      " 12  NumWebPurchases      2240 non-null   int64\n",
      " 13  NumCatalogPurchases  2240 non-null   int64\n",
      " 14  NumStorePurchases    2240 non-null   int64\n",
      " 15  NumWebVisitsMonth    2240 non-null   int64\n",
      " 16  AcceptedCmp1         2240 non-null   int64\n",
      " 17  AcceptedCmp2         2240 non-null   int64\n",
      " 18  AcceptedCmp3         2240 non-null   int64\n",
      " 19  AcceptedCmp4         2240 non-null   int64\n",
      " 20  AcceptedCmp5         2240 non-null   int64\n",
      " 21  Response             2240 non-null   int64\n",
      " 22  Complain             2240 non-null   int64\n",
      "dtypes: int64(23)\n",
      "memory usage: 402.6 KB\n",
      "None\n",
      "------------------------------------------------------------\n",
      "Data Type: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Education       2240 non-null   object\n",
      " 1   Marital_Status  2240 non-null   object\n",
      " 2   Income          2216 non-null   object\n",
      " 3   Dt_Customer     2240 non-null   object\n",
      " 4   Country         2240 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 87.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data Types and Value Counts\n",
    "dtype_counts = data.dtypes.value_counts()\n",
    "print(\"Datatypes in the dataset and their respective value counts:\")\n",
    "print(dtype_counts)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Detailed breakdown of data types with column names\n",
    "print(\"Data Type: int64\")\n",
    "print(data.select_dtypes(include='int64').info())\n",
    "print(\"-\" * 60)\n",
    "print(\"Data Type: object\")\n",
    "print(data.select_dtypes(include='object').info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb6a81e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#e6e6fa; padding:10px\">The above output presents a summary of the dataset's data types and their respective value counts, followed by a detailed breakdown of each data type category (int64 and object) with column names, non-null counts, and data types.\n",
    "\n",
    "<b>1. Datatypes in the dataset and their respective value counts:</b><br>\n",
    "    &nbsp;&nbsp;&nbsp;It indicates that there are <i>23 columns</i> with data type <i>int64</i> and <i>5 columns</i> with data type <i>object</i>.<br>\n",
    "&nbsp;&nbsp;&nbsp;The value counts for each data type are presented in a Series format.<br>\n",
    "<b>2. Detailed breakdown of data types with column names:</b><br>\n",
    "    <i>For columns of data type int64:</i><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It displays a DataFrame summary with 23 columns.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Each column's name, non-null count, and data type (Dtype) are provided.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The summary is followed by memory usage information.<br>\n",
    "    <i>For columns of data type object:</i><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It displays another DataFrame summary with 5 columns.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Similar to int64, it presents column names, non-null counts, and data types (Dtype).<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Memory usage information is also provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6ffa0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values and Percentage:\n",
      "                     Missing Values  Percentage\n",
      "ID                                0    0.000000\n",
      "Year_Birth                        0    0.000000\n",
      "Education                         0    0.000000\n",
      "Marital_Status                    0    0.000000\n",
      "Income                           24    1.071429\n",
      "Kidhome                           0    0.000000\n",
      "Teenhome                          0    0.000000\n",
      "Dt_Customer                       0    0.000000\n",
      "Country                           0    0.000000\n",
      "Recency                           0    0.000000\n",
      "MntWines                          0    0.000000\n",
      "MntFruits                         0    0.000000\n",
      "MntMeatProducts                   0    0.000000\n",
      "MntFishProducts                   0    0.000000\n",
      "MntSweetProducts                  0    0.000000\n",
      "MntGoldProds                      0    0.000000\n",
      "NumDealsPurchases                 0    0.000000\n",
      "NumWebPurchases                   0    0.000000\n",
      "NumCatalogPurchases               0    0.000000\n",
      "NumStorePurchases                 0    0.000000\n",
      "NumWebVisitsMonth                 0    0.000000\n",
      "AcceptedCmp1                      0    0.000000\n",
      "AcceptedCmp2                      0    0.000000\n",
      "AcceptedCmp3                      0    0.000000\n",
      "AcceptedCmp4                      0    0.000000\n",
      "AcceptedCmp5                      0    0.000000\n",
      "Response                          0    0.000000\n",
      "Complain                          0    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = (missing_values / len(data)) * 100\n",
    "\n",
    "# Create a DataFrame to display missing values and their percentage\n",
    "missing_info = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "\n",
    "# Print the missing information\n",
    "print(\"Missing Values and Percentage:\")\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637f192",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#e6e6fa; padding:10px\">It appears that the values in <b>'Income'</b> are formatted as currency with a dollar sign ('$') and commas (',') as thousand separators.<br>\n",
    "To convert these values to numeric format, we need to remove the dollar sign and commas from each value before converting them to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41d18fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_17372\\4244439147.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data['Income'] = data['Income'].str.replace('$', '').str.replace(',', '').astype(float).astype('Int64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       84835\n",
       "1       57091\n",
       "2       67267\n",
       "3       32474\n",
       "4       21474\n",
       "        ...  \n",
       "2235    66476\n",
       "2236    31056\n",
       "2237    46310\n",
       "2238    65819\n",
       "2239    94871\n",
       "Name: Income, Length: 2240, dtype: Int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dollar sign and commas, convert to float, and then to int\n",
    "data['Income'] = data['Income'].str.replace('$', '').str.replace(',', '').astype(float).astype('Int64')\n",
    "\n",
    "# Print the DataFrame to verify the update\n",
    "data['Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3317f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Income: 52247\n",
      "      ID  Year_Birth   Education Marital_Status  Income  Kidhome  Teenhome  \\\n",
      "0   1826        1970  Graduation       Divorced   84835        0         0   \n",
      "1      1        1961  Graduation         Single   57091        0         0   \n",
      "2  10476        1958  Graduation        Married   67267        0         1   \n",
      "3   1386        1967  Graduation       Together   32474        1         1   \n",
      "4   5371        1989  Graduation         Single   21474        1         0   \n",
      "\n",
      "  Dt_Customer Country  Recency  ...  NumCatalogPurchases  NumStorePurchases  \\\n",
      "0     6/16/14      SP        0  ...                    4                  6   \n",
      "1     6/15/14      CA        0  ...                    3                  7   \n",
      "2     5/13/14      US        0  ...                    2                  5   \n",
      "3     5/11/14     AUS        0  ...                    0                  2   \n",
      "4      4/8/14      SP        0  ...                    1                  2   \n",
      "\n",
      "   NumWebVisitsMonth  AcceptedCmp1  AcceptedCmp2  AcceptedCmp3  AcceptedCmp4  \\\n",
      "0                  1             0             0             0             0   \n",
      "1                  5             0             1             0             0   \n",
      "2                  2             0             0             0             0   \n",
      "3                  7             0             0             0             0   \n",
      "4                  7             0             0             1             0   \n",
      "\n",
      "   AcceptedCmp5  Response  Complain  \n",
      "0             0         1         0  \n",
      "1             0         1         0  \n",
      "2             0         0         0  \n",
      "3             0         0         0  \n",
      "4             0         1         0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of the 'Income' column\n",
    "income_mean = int(data['Income'].mean())\n",
    "\n",
    "# Print the mean of the 'Income' column\n",
    "print(\"Mean of Income:\", income_mean)\n",
    "\n",
    "# Fill missing values in 'Income' column with mean\n",
    "data['Income'].fillna(income_mean, inplace=True)\n",
    "\n",
    "# Print the DataFrame to verify the update\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e90a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "ID                     0\n",
      "Year_Birth             0\n",
      "Education              0\n",
      "Marital_Status         0\n",
      "Income                 0\n",
      "Kidhome                0\n",
      "Teenhome               0\n",
      "Dt_Customer            0\n",
      "Country                0\n",
      "Recency                0\n",
      "MntWines               0\n",
      "MntFruits              0\n",
      "MntMeatProducts        0\n",
      "MntFishProducts        0\n",
      "MntSweetProducts       0\n",
      "MntGoldProds           0\n",
      "NumDealsPurchases      0\n",
      "NumWebPurchases        0\n",
      "NumCatalogPurchases    0\n",
      "NumStorePurchases      0\n",
      "NumWebVisitsMonth      0\n",
      "AcceptedCmp1           0\n",
      "AcceptedCmp2           0\n",
      "AcceptedCmp3           0\n",
      "AcceptedCmp4           0\n",
      "AcceptedCmp5           0\n",
      "Response               0\n",
      "Complain               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# After replace missing values in 'Income' column confirm again for missing values\n",
    "missing_val = data.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a66bb7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#e6e6fa; padding:10px\">We replaced 24 missing values in income with the mean of the income. Hence, there is no missing values as of now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "792d18c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Education:\n",
      "['Graduation' 'PhD' '2n Cycle' 'Master' 'Basic']\n",
      "Unique values in Marital_Status:\n",
      "['Divorced' 'Single' 'Married' 'Together' 'Widow' 'YOLO' 'Alone' 'Absurd']\n",
      "Unique values in Country:\n",
      "['SP' 'CA' 'US' 'AUS' 'GER' 'IND' 'SA' 'ME']\n"
     ]
    }
   ],
   "source": [
    "# Data Consistency\n",
    "# Check for consistency in categorical variables\n",
    "categorical_variables = ['Education', 'Marital_Status', 'Country']\n",
    "for col in categorical_variables:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0b37485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate IDs:\n",
      "Empty DataFrame\n",
      "Columns: [ID, Year_Birth, Education, Marital_Status, Income, Kidhome, Teenhome, Dt_Customer, Country, Recency, MntWines, MntFruits, MntMeatProducts, MntFishProducts, MntSweetProducts, MntGoldProds, NumDealsPurchases, NumWebPurchases, NumCatalogPurchases, NumStorePurchases, NumWebVisitsMonth, AcceptedCmp1, AcceptedCmp2, AcceptedCmp3, AcceptedCmp4, AcceptedCmp5, Response, Complain]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "Summary after cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   2240 non-null   int64 \n",
      " 1   Year_Birth           2240 non-null   int64 \n",
      " 2   Education            2240 non-null   object\n",
      " 3   Marital_Status       2240 non-null   object\n",
      " 4   Income               2240 non-null   Int64 \n",
      " 5   Kidhome              2240 non-null   int64 \n",
      " 6   Teenhome             2240 non-null   int64 \n",
      " 7   Dt_Customer          2240 non-null   object\n",
      " 8   Country              2240 non-null   object\n",
      " 9   Recency              2240 non-null   int64 \n",
      " 10  MntWines             2240 non-null   int64 \n",
      " 11  MntFruits            2240 non-null   int64 \n",
      " 12  MntMeatProducts      2240 non-null   int64 \n",
      " 13  MntFishProducts      2240 non-null   int64 \n",
      " 14  MntSweetProducts     2240 non-null   int64 \n",
      " 15  MntGoldProds         2240 non-null   int64 \n",
      " 16  NumDealsPurchases    2240 non-null   int64 \n",
      " 17  NumWebPurchases      2240 non-null   int64 \n",
      " 18  NumCatalogPurchases  2240 non-null   int64 \n",
      " 19  NumStorePurchases    2240 non-null   int64 \n",
      " 20  NumWebVisitsMonth    2240 non-null   int64 \n",
      " 21  AcceptedCmp1         2240 non-null   int64 \n",
      " 22  AcceptedCmp2         2240 non-null   int64 \n",
      " 23  AcceptedCmp3         2240 non-null   int64 \n",
      " 24  AcceptedCmp4         2240 non-null   int64 \n",
      " 25  AcceptedCmp5         2240 non-null   int64 \n",
      " 26  Response             2240 non-null   int64 \n",
      " 27  Complain             2240 non-null   int64 \n",
      "dtypes: Int64(1), int64(23), object(4)\n",
      "memory usage: 492.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Standardize 'Marital_Status' column\n",
    "data['Marital_Status'] = data['Marital_Status'].str.upper()\n",
    "\n",
    "# Check for duplicates in 'ID' column\n",
    "duplicate_ids = data[data.duplicated(subset=['ID'])]\n",
    "print(\"Duplicate IDs:\")\n",
    "print(duplicate_ids)\n",
    "\n",
    "# Display summary after cleaning\n",
    "print(\"Summary after cleaning:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54e47b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Country</th>\n",
       "      <th>Recency</th>\n",
       "      <th>...</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>Response</th>\n",
       "      <th>Complain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1826</td>\n",
       "      <td>1970</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>84835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/16/14</td>\n",
       "      <td>SP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1961</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>57091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/15/14</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10476</td>\n",
       "      <td>1958</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>67267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5/13/14</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1386</td>\n",
       "      <td>1967</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>TOGETHER</td>\n",
       "      <td>32474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5/11/14</td>\n",
       "      <td>AUS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5371</td>\n",
       "      <td>1989</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>21474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4/8/14</td>\n",
       "      <td>SP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Year_Birth   Education Marital_Status  Income  Kidhome  Teenhome  \\\n",
       "0   1826        1970  Graduation       DIVORCED   84835        0         0   \n",
       "1      1        1961  Graduation         SINGLE   57091        0         0   \n",
       "2  10476        1958  Graduation        MARRIED   67267        0         1   \n",
       "3   1386        1967  Graduation       TOGETHER   32474        1         1   \n",
       "4   5371        1989  Graduation         SINGLE   21474        1         0   \n",
       "\n",
       "  Dt_Customer Country  Recency  ...  NumCatalogPurchases  NumStorePurchases  \\\n",
       "0     6/16/14      SP        0  ...                    4                  6   \n",
       "1     6/15/14      CA        0  ...                    3                  7   \n",
       "2     5/13/14      US        0  ...                    2                  5   \n",
       "3     5/11/14     AUS        0  ...                    0                  2   \n",
       "4      4/8/14      SP        0  ...                    1                  2   \n",
       "\n",
       "   NumWebVisitsMonth  AcceptedCmp1  AcceptedCmp2  AcceptedCmp3  AcceptedCmp4  \\\n",
       "0                  1             0             0             0             0   \n",
       "1                  5             0             1             0             0   \n",
       "2                  2             0             0             0             0   \n",
       "3                  7             0             0             0             0   \n",
       "4                  7             0             0             1             0   \n",
       "\n",
       "   AcceptedCmp5  Response  Complain  \n",
       "0             0         1         0  \n",
       "1             0         1         0  \n",
       "2             0         0         0  \n",
       "3             0         0         0  \n",
       "4             0         1         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a909dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid dates:\n",
      "Series([], Name: Dt_Customer, dtype: datetime64[ns])\n",
      "Summary after cleaning:\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Series name: Dt_Customer\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "2240 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 17.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Standardize the 'Dt_Customer' column to the 'mm/dd/yy' format\n",
    "data['Dt_Customer'] = pd.to_datetime(data['Dt_Customer'], errors='coerce')\n",
    "\n",
    "# Check for any dates that could not be parsed\n",
    "invalid_dates = data[data['Dt_Customer'].isnull()]['Dt_Customer']\n",
    "print(\"Invalid dates:\")\n",
    "print(invalid_dates)\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "data.dropna(subset=['Dt_Customer'], inplace=True)\n",
    "\n",
    "# Display summary after cleaning\n",
    "print(\"Summary after cleaning:\")\n",
    "print(data['Dt_Customer'].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050af8cc",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#e6e6fa; padding:10px\">This above code aims to standardize the date format in the 'Dt_Customer' column and handle any invalid dates that may be present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27517778",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\">\n",
    "<h3>3. To create a data quality report with univariate analysis for both continuous and categorical variables: </h3>\n",
    "\n",
    "***Continuous Variables:*** \n",
    "+ Calculate the percentage of missing values.\n",
    "+ Compute the percentage of terms which are zero.\n",
    "+ Calculate descriptive statistics (mean, percentiles, min, max).\n",
    "+ Generate a summary report.\n",
    "\n",
    "***Categorical Variables:***\n",
    "+ Calculate the percentage of missing values.\n",
    "+ Determine the number of unique values.\n",
    "+ Generate a summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14334b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Data :\n",
      "Index(['ID', 'Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency',\n",
      "       'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
      "       'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases',\n",
      "       'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n",
      "       'NumWebVisitsMonth', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3',\n",
      "       'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'Complain'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical Data\n",
      "Index(['Education', 'Marital_Status', 'Country'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Select the Continuous data\n",
    "cont = data.select_dtypes(include=np.number)\n",
    "print(\"Continuous Data :\")\n",
    "print(cont.columns)\n",
    "\n",
    "#Select the Categorical data\n",
    "catg = data.select_dtypes(include=object)\n",
    "print(\"\\n\"\"Categorical Data\")\n",
    "print(catg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa286441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables Analysis:\n",
      "\n",
      "             Income      Kidhome     Teenhome      Recency     MntWines  \\\n",
      "count        2240.0  2240.000000  2240.000000  2240.000000  2240.000000   \n",
      "mean   52247.248661     0.444196     0.506250    49.109375   303.935714   \n",
      "std    25037.797168     0.538398     0.544538    28.962453   336.597393   \n",
      "min          1730.0     0.000000     0.000000     0.000000     0.000000   \n",
      "25%        35538.75     0.000000     0.000000    24.000000    23.750000   \n",
      "50%         51741.5     0.000000     0.000000    49.000000   173.500000   \n",
      "75%        68289.75     1.000000     1.000000    74.000000   504.250000   \n",
      "90%         79800.3     1.000000     1.000000    89.000000   822.100000   \n",
      "95%         83927.0     1.000000     1.000000    94.000000  1000.000000   \n",
      "max        666666.0     2.000000     2.000000    99.000000  1493.000000   \n",
      "\n",
      "         MntFruits  MntMeatProducts  MntFishProducts  MntSweetProducts  \\\n",
      "count  2240.000000      2240.000000      2240.000000       2240.000000   \n",
      "mean     26.302232       166.950000        37.525446         27.062946   \n",
      "std      39.773434       225.715373        54.628979         41.280498   \n",
      "min       0.000000         0.000000         0.000000          0.000000   \n",
      "25%       1.000000        16.000000         3.000000          1.000000   \n",
      "50%       8.000000        67.000000        12.000000          8.000000   \n",
      "75%      33.000000       232.000000        50.000000         33.000000   \n",
      "90%      83.000000       499.000000       120.000000         89.000000   \n",
      "95%     123.000000       687.100000       168.050000        126.000000   \n",
      "max     199.000000      1725.000000       259.000000        263.000000   \n",
      "\n",
      "       MntGoldProds  ...  NumCatalogPurchases  NumStorePurchases  \\\n",
      "count   2240.000000  ...          2240.000000        2240.000000   \n",
      "mean      44.021875  ...             2.662054           5.790179   \n",
      "std       52.167439  ...             2.923101           3.250958   \n",
      "min        0.000000  ...             0.000000           0.000000   \n",
      "25%        9.000000  ...             0.000000           3.000000   \n",
      "50%       24.000000  ...             2.000000           5.000000   \n",
      "75%       56.000000  ...             4.000000           8.000000   \n",
      "90%      122.000000  ...             7.000000          11.000000   \n",
      "95%      165.050000  ...             9.000000          12.000000   \n",
      "max      362.000000  ...            28.000000          13.000000   \n",
      "\n",
      "       NumWebVisitsMonth  AcceptedCmp1  AcceptedCmp2  AcceptedCmp3  \\\n",
      "count        2240.000000   2240.000000   2240.000000   2240.000000   \n",
      "mean            5.316518      0.064286      0.013393      0.072768   \n",
      "std             2.426645      0.245316      0.114976      0.259813   \n",
      "min             0.000000      0.000000      0.000000      0.000000   \n",
      "25%             3.000000      0.000000      0.000000      0.000000   \n",
      "50%             6.000000      0.000000      0.000000      0.000000   \n",
      "75%             7.000000      0.000000      0.000000      0.000000   \n",
      "90%             8.000000      0.000000      0.000000      0.000000   \n",
      "95%             8.000000      1.000000      0.000000      1.000000   \n",
      "max            20.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "       AcceptedCmp4  AcceptedCmp5     Response     Complain  \n",
      "count   2240.000000   2240.000000  2240.000000  2240.000000  \n",
      "mean       0.074554      0.072768     0.149107     0.009375  \n",
      "std        0.262728      0.259813     0.356274     0.096391  \n",
      "min        0.000000      0.000000     0.000000     0.000000  \n",
      "25%        0.000000      0.000000     0.000000     0.000000  \n",
      "50%        0.000000      0.000000     0.000000     0.000000  \n",
      "75%        0.000000      0.000000     0.000000     0.000000  \n",
      "90%        0.000000      0.000000     1.000000     0.000000  \n",
      "95%        1.000000      1.000000     1.000000     0.000000  \n",
      "max        1.000000      1.000000     1.000000     1.000000  \n",
      "\n",
      "[10 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Continuous Variables Analysis\n",
    "continuous_vars = ['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits', \n",
    "                   'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', \n",
    "                   'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', \n",
    "                   'NumWebVisitsMonth', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', \n",
    "                   'AcceptedCmp5', 'Response', 'Complain']\n",
    "\n",
    "## Calculate statistics for continuous variables\n",
    "continuous_stats = data[continuous_vars].describe(percentiles=[0.25, 0.5, 0.75, 0.90, 0.95])\n",
    "\n",
    "# Display the analysis\n",
    "print(\"Continuous Variables Analysis:\"\"\\n\")\n",
    "print(continuous_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e98214",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\">The above table provides descriptive statistics for various continuous variables in your dataset. Here's what each statistic represents:<br>\n",
    "    \n",
    "+ count: This represents the number of valid (non-missing) observations for each variable. It indicates the size of the dataset for that particular variable.\n",
    "+ mean: The mean (average) of a variable is calculated by summing all the values of the variable and dividing by the total number of observations. It gives you a measure of the central tendency of the data.\n",
    "+ std: The standard deviation is a measure of the dispersion or spread of the values around the mean. A higher standard deviation indicates greater variability in the data, while a lower standard deviation indicates less variability.\n",
    "+ min: This is the smallest value observed in the dataset for each variable. It represents the lower bound of the range of values.\n",
    "+ 25% (1st Quartile): Also known as the first quartile or lower quartile, this value indicates the point below which 25% of the observations fall. It's the value that separates the lowest 25% of the data from the rest.\n",
    "+ 50% (2nd Quartile/Median): The median is the middle value of the dataset when the observations are arranged in ascending order. It represents the value below which 50% of the observations fall.\n",
    "+ 75% (3rd Quartile): The third quartile or upper quartile indicates the point below which 75% of the observations fall. It's the value that separates the lowest 75% of the data from the highest 25%.\n",
    "+ 90%: This value indicates the point below which 90% of the observations fall. It provides insight into the distribution of the data towards the lower end.\n",
    "+ 95%: Similar to the 90th percentile, this value indicates the point below which 95% of the observations fall, providing further insight into the distribution of the data towards the lower end.\n",
    "+ max: This is the largest value observed in the dataset for each variable. It represents the upper bound of the range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90954597",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\">The above table provides descriptive statistics for various continuous variables in your dataset. Here's what each statistic represents:<br>\n",
    "    \n",
    "+ **count:** The number of non-missing values for each variable.\n",
    "+ **mean:** The average value of each variable.\n",
    "+ **std:** The standard deviation, which measures the dispersion or spread of the values.\n",
    "+ **min:** The minimum value observed for each variable.\n",
    "+ **25%:** The 25th percentile (first quartile), indicating the value below which 25% of the data fall.\n",
    "+ **50%:** The median (second quartile), representing the middle value when the data is sorted in ascending order.\n",
    "+ **75%:** The 75th percentile (third quartile), indicating the value below which 75% of the data fall.\n",
    "+ **90%:** The 90th percentile, indicating the value below which 90% of the data fall.\n",
    "+ **95%:** The 95th percentile, indicating the value below which 95% of the data fall.\n",
    "+ **max:** The maximum value observed for each variable.\n",
    "\n",
    "*For example,* in the \"Income\" variable, the mean income is approximately **52,247.25**, with a standard deviation of approximately **25,037.80**. The minimum income observed is **1,730**, and the maximum income observed is **666,666**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de3103f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Variables Analysis:\n",
      "\n",
      "                % Missing Values  Unique Values\n",
      "Education                    0.0              5\n",
      "Marital_Status               0.0              8\n",
      "Country                      0.0              8\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of missing values\n",
    "missing_values_cat = catg.isnull().mean() * 100\n",
    "\n",
    "# Determine number of unique values\n",
    "unique_values = catg.nunique()\n",
    "\n",
    "# Combine the results\n",
    "categorical_analysis = pd.concat([missing_values_cat, unique_values], axis=1)\n",
    "categorical_analysis.columns = ['% Missing Values', 'Unique Values']\n",
    "\n",
    "# Display the analysis\n",
    "print(\"Categorical Variables Analysis:\\n\")\n",
    "print(categorical_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e9235",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#fff9c4; padding:10px\">Above analysis provides insights into the categorical variables in your dataset:\n",
    "\n",
    "1. **% Missing Values**: This indicates the percentage of missing values (if any) in each categorical variable. A missing value implies that the information for that variable is not available for certain observations in your dataset. In this case, there are no missing values for any of the categorical variables, as the percentage is 0.0 for all of them.\n",
    "\n",
    "2. **Unique Values**: This represents the count of unique categories or levels within each categorical variable. It gives you an idea of the diversity or variability present in the data for each categorical variable. For example:\n",
    "   - **Education**: There are 5 unique values or levels, indicating 5 different education categories among the observations.\n",
    "   - **Marital_Status**: There are 8 unique values or levels, suggesting 8 different marital status categories.\n",
    "   - **Country**: There are 8 unique values or levels, implying that the dataset includes data from 8 different countries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c35bf",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#e6e6fa; padding:10px\"><h3>4. \n",
    "To identify extreme values or outliers in variables representing income, amount of money spent on various categories, and recency of purchase :</h3>\n",
    "\n",
    "1. **Income**: Look for values that are significantly higher or lower than the majority of the data. You can calculate the interquartile range (IQR) and then identify values that are more than 1.5 times the IQR above the third quartile (Q3) or below the first quartile (Q1).\n",
    "\n",
    "2. **Amount of money spent on various categories**: Follow a similar approach as with income. Calculate the IQR for each spending category and identify values that fall outside the 1.5 times IQR range above Q3 or below Q1.\n",
    "\n",
    "3. **Recency of purchase**: Examine values that are significantly higher than the typical range of recency values. This could indicate customers who haven't made purchases for an unusually long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ece0f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers for Income: 8\n",
      "Number of outliers for MntWines: 35\n",
      "Number of outliers for MntFruits: 227\n",
      "Number of outliers for MntMeatProducts: 175\n",
      "Number of outliers for MntFishProducts: 223\n",
      "Number of outliers for MntSweetProducts: 248\n",
      "Number of outliers for MntGoldProds: 207\n",
      "Number of outliers for Recency: 0\n"
     ]
    }
   ],
   "source": [
    "# Define the continuous variables of interest\n",
    "cont_vars = ['Income', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "                   'MntSweetProducts', 'MntGoldProds', 'Recency']\n",
    "\n",
    "# Calculate the interquartile range (IQR) for each continuous variable\n",
    "Q1 = data[cont_vars].quantile(0.25)\n",
    "Q3 = data[cont_vars].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers for each continuous variable\n",
    "outliers = (data[cont_vars] < (Q1 - 1.5 * IQR)) | (data[cont_vars] > (Q3 + 1.5 * IQR))\n",
    "\n",
    "# Print the count of outliers for each conti_vars\n",
    "for var in cont_vars:\n",
    "    print(f\"Number of outliers for {var}: {outliers[var].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7cc57",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; background-color:#e6e6fa; padding:10px\">This code is performing outlier detection for a set of continuous variables in a DataFrame. Here's a breakdown of each step:\n",
    "\n",
    "1. **Define Continuous Variables**: First, a list named `cont_vars` is defined, containing the names of continuous variables of interest.\n",
    "\n",
    "2. **Calculate Interquartile Range (IQR)**: The Interquartile Range (IQR) is calculated for each continuous variable using the `quantile` method with a parameter of 0.25 (Q1) and 0.75 (Q3) to get the first and third quartiles, respectively. Then, the IQR is computed as the difference between Q3 and Q1.\n",
    "\n",
    "3. **Identify Outliers**: Outliers for each continuous variable are identified using the IQR method. For each variable, a Boolean DataFrame is created where `True` indicates the presence of an outlier, calculated based on whether the value falls below `(Q1 - 1.5 * IQR)` or above `(Q3 + 1.5 * IQR)`.\n",
    "\n",
    "4. **Print Outlier Counts**: Finally, a loop iterates over each continuous variable in `cont_vars`. For each variable, it prints the count of outliers found by summing up the `True` values in the Boolean DataFrame created in the previous step for that variable.\n",
    "\n",
    "This process provides insight into whether there are any extreme values (outliers) for each selected continuous variable in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d4c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7158b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c41a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3eddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b6dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
